{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-06-15T17:20:52.889564757Z",
     "start_time": "2023-06-15T17:20:52.194993390Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import statistics\n",
    "from functools import reduce\n",
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "if os.environ.get('DISPLAY') is not None:\n",
    "    %matplotlib tk\n",
    "\n",
    "import msmfcode_src\n",
    "from msmfcode.core.logging import log\n",
    "from msmfcode.core.config import *\n",
    "from msmfcode.execution.parallel import ParallelExecutor, ParallelEvaluationExecutor\n",
    "from msmfcode.models.cann import DMSMF, FMSMF, Grid, SSSF\n",
    "from msmfcode.evaluation.plot import plot_weight_distribution, plot_neuron_activity_fixed_attractors, plot_neuron_activity_variable_attractors, plot_neuron_activity_static, save_plot, plot_distribution\n",
    "from msmfcode.evaluation.algorithms import calc_kls_sizes, calc_kls_locs\n",
    "\n",
    "# Configuration\n",
    "PLOT_FILE_TYPE = 'pdf'\n",
    "log.handlers[LogHandler.STREAM].setLevel(logging.DETAIL)\n",
    "log.handlers[LogHandler.FILE].setLevel(logging.DETAIL)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation - Single Run\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m> Starting experiment single-27: eval_2-1-b-01\u001B[0m\n",
      "\u001B[32m>> Starting evaluation run\u001B[0m\n",
      "\u001B[32m>> Starting batch run [1/2]\u001B[0m\n",
      "\u001B[32m>> Started all CAN simulations\u001B[0m\n",
      "\u001B[32m>> Finished all CAN simulations\u001B[0m\n",
      "\u001B[32m>> Starting batch run [2/2]\u001B[0m\n",
      "\u001B[32m>> Started all CAN simulations\u001B[0m\n",
      "\u001B[32m>> Finished all CAN simulations\u001B[0m\n",
      "\u001B[32m-------------------------------------------------------------------------------------\u001B[0m\n",
      "\u001B[32m>> Metrics after 20 runs:\u001B[0m\n",
      "\u001B[32m>> pos_error_mean_mean = 0.16\u001B[0m\n",
      "\u001B[32m>> pos_error_mean_min = 0.13\u001B[0m\n",
      "\u001B[32m>> pos_error_mean_max = 0.19\u001B[0m\n",
      "\u001B[32m>> pos_error_mean_std = 0.01\u001B[0m\n",
      "\u001B[32m>> pos_error_mean_median = 0.17\u001B[0m\n",
      "\u001B[32m>> pos_error_mean_q1 = 0.15\u001B[0m\n",
      "\u001B[32m>> pos_error_mean_q3 = 0.17\u001B[0m\n",
      "\u001B[32m>> pos_error_mean_whishi = 0.19\u001B[0m\n",
      "\u001B[32m>> pos_error_mean_whislo = 0.13\u001B[0m\n",
      "\u001B[32m>> pos_error_std_mean = 0.25\u001B[0m\n",
      "\u001B[32m>> pos_error_std_min = 0.23\u001B[0m\n",
      "\u001B[32m>> pos_error_std_max = 0.28\u001B[0m\n",
      "\u001B[32m>> pos_error_std_std = 0.01\u001B[0m\n",
      "\u001B[32m>> pos_error_std_median = 0.25\u001B[0m\n",
      "\u001B[32m>> pos_error_std_q1 = 0.25\u001B[0m\n",
      "\u001B[32m>> pos_error_std_q3 = 0.26\u001B[0m\n",
      "\u001B[32m>> pos_error_std_whishi = 0.28\u001B[0m\n",
      "\u001B[32m>> pos_error_std_whislo = 0.23\u001B[0m\n",
      "\u001B[32m>> pos_error_min_mean = 0.00\u001B[0m\n",
      "\u001B[32m>> pos_error_max_mean = 1.14\u001B[0m\n",
      "\u001B[32m>> pos_error_num_cat_mean = 0.00\u001B[0m\n",
      "\u001B[32m>> pos_error_num_cat_median = 0.00\u001B[0m\n",
      "\u001B[32m>> pos_error_num_cat_q1 = 0.00\u001B[0m\n",
      "\u001B[32m>> pos_error_num_cat_q3 = 0.00\u001B[0m\n",
      "\u001B[32m>> pos_error_num_cat_whishi = 0.00\u001B[0m\n",
      "\u001B[32m>> pos_error_num_cat_whislo = 0.00\u001B[0m\n",
      "\u001B[32m>> mean_field_activity_mean = 0.03\u001B[0m\n",
      "\u001B[32m>> mean_field_activity_min = 0.03\u001B[0m\n",
      "\u001B[32m>> mean_field_activity_max = 0.03\u001B[0m\n",
      "\u001B[32m>> mean_field_activity_std = 0.00\u001B[0m\n",
      "\u001B[32m>> mean_field_activity_median = 0.03\u001B[0m\n",
      "\u001B[32m>> mean_field_activity_q1 = 0.03\u001B[0m\n",
      "\u001B[32m>> mean_field_activity_q3 = 0.03\u001B[0m\n",
      "\u001B[32m>> mean_field_activity_whishi = 0.03\u001B[0m\n",
      "\u001B[32m>> mean_field_activity_whislo = 0.03\u001B[0m\n",
      "\u001B[32m>> perc_correct_fields_mean = 1.00\u001B[0m\n",
      "\u001B[32m>> perc_correct_fields_min = 1.00\u001B[0m\n",
      "\u001B[32m>> perc_correct_fields_max = 1.00\u001B[0m\n",
      "\u001B[32m>> perc_correct_fields_std = 0.00\u001B[0m\n",
      "\u001B[32m>> perc_correct_fields_median = 1.00\u001B[0m\n",
      "\u001B[32m>> perc_correct_fields_q1 = 1.00\u001B[0m\n",
      "\u001B[32m>> perc_correct_fields_q3 = 1.00\u001B[0m\n",
      "\u001B[32m>> perc_correct_fields_whishi = 1.00\u001B[0m\n",
      "\u001B[32m>> perc_correct_fields_whislo = 1.00\u001B[0m\n",
      "\u001B[32m>> avg_num_fields_per_neuron_mean = 12.00\u001B[0m\n",
      "\u001B[32m>> avg_num_fields_per_neuron_std = 0.00\u001B[0m\n",
      "\u001B[32m>> avg_num_fields_active_per_neuron_mean = 12.00\u001B[0m\n",
      "\u001B[32m>> avg_num_fields_active_per_neuron_std = 0.00\u001B[0m\n",
      "\u001B[32m>> avg_accum_field_coverage_per_neuron_mean = 24.00\u001B[0m\n",
      "\u001B[32m>> avg_accum_field_coverage_per_neuron_std = 0.00\u001B[0m\n",
      "\u001B[32m>> activity_false_positives_num_mean = 17374.85\u001B[0m\n",
      "\u001B[32m>> activity_false_positives_num_min = 17329.00\u001B[0m\n",
      "\u001B[32m>> activity_false_positives_num_max = 17403.00\u001B[0m\n",
      "\u001B[32m>> activity_false_positives_num_std = 18.26\u001B[0m\n",
      "\u001B[32m>> activity_false_positives_num_median = 17377.50\u001B[0m\n",
      "\u001B[32m>> activity_false_positives_num_q1 = 17365.50\u001B[0m\n",
      "\u001B[32m>> activity_false_positives_num_q3 = 17385.50\u001B[0m\n",
      "\u001B[32m>> activity_false_positives_num_whishi = 17403.00\u001B[0m\n",
      "\u001B[32m>> activity_false_positives_num_whislo = 17342.00\u001B[0m\n",
      "\u001B[32m>> activity_false_negatives_num_mean = 0.00\u001B[0m\n",
      "\u001B[32m>> activity_false_negatives_num_min = 0.00\u001B[0m\n",
      "\u001B[32m>> activity_false_negatives_num_max = 0.00\u001B[0m\n",
      "\u001B[32m>> activity_false_negatives_num_std = 0.00\u001B[0m\n",
      "\u001B[32m>> activity_false_negatives_num_median = 0.00\u001B[0m\n",
      "\u001B[32m>> activity_false_negatives_num_q1 = 0.00\u001B[0m\n",
      "\u001B[32m>> activity_false_negatives_num_q3 = 0.00\u001B[0m\n",
      "\u001B[32m>> activity_false_negatives_num_whishi = 0.00\u001B[0m\n",
      "\u001B[32m>> activity_false_negatives_num_whislo = 0.00\u001B[0m\n",
      "\u001B[32m>> perc_unique_field_combinations_mean = 0.98\u001B[0m\n",
      "\u001B[32m>> perc_unique_field_combinations_min = 0.97\u001B[0m\n",
      "\u001B[32m>> perc_unique_field_combinations_max = 0.99\u001B[0m\n",
      "\u001B[32m>> perc_unique_field_combinations_std = 0.01\u001B[0m\n",
      "\u001B[32m>> perc_unique_field_combinations_median = 0.98\u001B[0m\n",
      "\u001B[32m>> perc_unique_field_combinations_q1 = 0.97\u001B[0m\n",
      "\u001B[32m>> perc_unique_field_combinations_q3 = 0.98\u001B[0m\n",
      "\u001B[32m>> perc_unique_field_combinations_whishi = 0.99\u001B[0m\n",
      "\u001B[32m>> perc_unique_field_combinations_whislo = 0.97\u001B[0m\n",
      "\u001B[32m>> weighted_avg_activity_mean = 59.58\u001B[0m\n",
      "\u001B[32m>> weighted_avg_activity_std = 0.00\u001B[0m\n",
      "\u001B[32m>> weighted_avg_activity_median = 59.58\u001B[0m\n",
      "\u001B[32m>> weighted_avg_activity_q1 = 59.58\u001B[0m\n",
      "\u001B[32m>> weighted_avg_activity_q3 = 59.58\u001B[0m\n",
      "\u001B[32m>> weighted_avg_activity_whishi = 59.58\u001B[0m\n",
      "\u001B[32m>> weighted_avg_activity_whislo = 59.57\u001B[0m\n",
      "\u001B[32m-------------------------------------------------------------------------------------\u001B[0m\n",
      "\u001B[32m> Finished experiment single-27 in 2.83 seconds.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "experiment_id = 'single'\n",
    "\n",
    "pe = ParallelExecutor(experiment_id, FMSMF)\n",
    "pe.run()\n",
    "\n",
    "\n",
    "# pe_ = deepcopy(pe)\n",
    "#\n",
    "# for i in range(len(pe.cans)):\n",
    "#     pe.cans[i].p.I = 0\n",
    "#     # pe.cans[i].p.J1 = 0\n",
    "#     # pe.cans[i].p.field_ratio_threshold = 0.99\n",
    "#\n",
    "# pe.run(reset_fields=False, reset_weights=True)\n",
    "\n",
    "# num_fields = np.sum(pe.cans[0].field_sizes > 0)\n",
    "# avg_field_size = np.sum(pe.cans[0].field_sizes) / num_fields\n",
    "# print(f'Avg field size: {avg_field_size}')\n",
    "\n",
    "\n",
    "\n",
    "# pe.cans[0].plot(pos_range=range(100, 160))\n",
    "\n",
    "# plot_neuron_activity_static(pe.cans[0], neuron_range=[0,1,2,3,4])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T17:21:26.392921916Z",
     "start_time": "2023-06-15T17:21:23.453077335Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "\n",
    "pe.cans[0].plot(pos_range=range(180, 280))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-03-31T20:13:01.852758Z",
     "end_time": "2023-03-31T20:13:54.134120Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [15]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mplot_neuron_activity_fixed_attractors\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcans\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpause_time\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3.0\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/code/personal_research/spytial/spytial/evaluation/plot.py:327\u001B[0m, in \u001B[0;36mplot_neuron_activity_fixed_attractors\u001B[0;34m(net, neuron_range, pause_time)\u001B[0m\n\u001B[1;32m    325\u001B[0m \u001B[38;5;66;03m# Draw, wait and clear the previous data from the plot\u001B[39;00m\n\u001B[1;32m    326\u001B[0m plt\u001B[38;5;241m.\u001B[39mdraw()\n\u001B[0;32m--> 327\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpause\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpause_time\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    328\u001B[0m axis[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mclear()\n\u001B[1;32m    329\u001B[0m axis[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mclear()\n",
      "File \u001B[0;32m~/code/personal_research/spytial/venv/lib/python3.8/site-packages/matplotlib/pyplot.py:567\u001B[0m, in \u001B[0;36mpause\u001B[0;34m(interval)\u001B[0m\n\u001B[1;32m    565\u001B[0m         canvas\u001B[38;5;241m.\u001B[39mdraw_idle()\n\u001B[1;32m    566\u001B[0m     show(block\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m--> 567\u001B[0m     \u001B[43mcanvas\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart_event_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43minterval\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    568\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    569\u001B[0m     time\u001B[38;5;241m.\u001B[39msleep(interval)\n",
      "File \u001B[0;32m~/code/personal_research/spytial/venv/lib/python3.8/site-packages/matplotlib/backends/_backend_tk.py:385\u001B[0m, in \u001B[0;36mFigureCanvasTk.start_event_loop\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    382\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    383\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_event_loop_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tkcanvas\u001B[38;5;241m.\u001B[39mafter_idle(\n\u001B[1;32m    384\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstop_event_loop)\n\u001B[0;32m--> 385\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tkcanvas\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmainloop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/lib/python3.8/tkinter/__init__.py:1429\u001B[0m, in \u001B[0;36mMisc.mainloop\u001B[0;34m(self, n)\u001B[0m\n\u001B[1;32m   1427\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmainloop\u001B[39m(\u001B[38;5;28mself\u001B[39m, n\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m):\n\u001B[1;32m   1428\u001B[0m     \u001B[38;5;124;03m\"\"\"Call the mainloop of Tk.\"\"\"\u001B[39;00m\n\u001B[0;32m-> 1429\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtk\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmainloop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "plot_neuron_activity_fixed_attractors(pe.cans[0], pause_time=3.0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: -0.5193361050091689\n",
      "Min: -1.4790213944420878\n",
      "Max: 0.0\n",
      "Nw>0: 2450\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean: {np.mean(pe.cans[0].W)}')\n",
    "print(f'Min: {np.min(pe.cans[0].W)}')\n",
    "print(f'Max: {np.max(pe.cans[0].W)}')\n",
    "print(f'Nw>0: {np.count_nonzero(pe.cans[0].W)}')\n",
    "\n",
    "a = plt.hist(pe.cans[0].W.flatten())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: -0.24637800045999966\n",
      "Min: -0.8311357933607728\n",
      "Max: 0.004999999999999998\n",
      "Nw>0: 2450\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean: {np.mean(pe.cans[0].W)}')\n",
    "print(f'Min: {np.min(pe.cans[0].W)}')\n",
    "print(f'Max: {np.max(pe.cans[0].W)}')\n",
    "print(f'Nw>0: {np.count_nonzero(pe.cans[0].W)}')\n",
    "\n",
    "a = plt.hist(pe.cans[0].W.flatten())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# pe.experiment_num = 11\n",
    "pe.save_data(save_plot=False, save_model=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# np.mean(self.m) * self.p.num_neurons * self.p.env_length\n",
    "\n",
    "print(np.mean(pe.cans[0].m[0,:]))\n",
    "print(np.mean(pea.cans[0].m[0,:]))\n",
    "\n",
    "print(pe.cans[0].p.num_neurons_per_module)\n",
    "print(pea.cans[0].p.num_neurons_per_module)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Find id of best/worst performing network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ID = 2\n",
      "Worst ID = 7\n"
     ]
    }
   ],
   "source": [
    "# Code\n",
    "pos_error_mean = pe.eval_data.eval_metrics[Metric.POS_ERROR_MEAN].values\n",
    "net_ids_sorted = np.argsort(pos_error_mean)\n",
    "\n",
    "print(f'Best ID = {net_ids_sorted[0]}')\n",
    "print(f'Worst ID = {net_ids_sorted[-1]}')\n",
    "\n",
    "best_net_id = net_ids_sorted[0]\n",
    "worst_net_id = net_ids_sorted[-1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot: Metric values for all CANs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#\n",
    "# Plot mean error distribution\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "metric = Metric.POS_ERROR_MEAN\n",
    "global_metric = 'mean'\n",
    "metric_name = f'{metric}_{global_metric}'\n",
    "\n",
    "plt.hist(pe.eval_data.eval_metrics[metric].values, bins=40)\n",
    "print(f'Mean: {pe.eval_data.eval_metrics[metric].mean}')\n",
    "print(f'Median: {pe.eval_data.eval_metrics[metric].median}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot: Fields of CAN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# plot_neuron_activity_static(pe.cans[0], neuron_range=range(5), save_plot=True, fig_type_name='3-1-b-s-03a')\n",
    "# plot_neuron_activity_static(pe_dead.cans[0], neuron_range=range(5, 10))\n",
    "plot_neuron_activity_static(pe.cans[0], neuron_range=range(10))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T09:48:27.090122Z",
     "end_time": "2023-04-24T09:48:28.037948Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "pe.cans[7].plot(pos_range=range(100, 160))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Perform subsequent experiment with lesions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "experiment_id = 'single'\n",
    "\n",
    "pe_dead = copy.deepcopy(pe)\n",
    "\n",
    "pe_dead.init_eval_data()\n",
    "\n",
    "# pe = ParallelExecutor(experiment_id, DMSMF)\n",
    "for i_can in range(len(pe_dead.cans)):\n",
    "    pe_dead.cans[i_can].p.prob_dead_neurons = 0.3\n",
    "    pe_dead.cans[i_can].set_dead_neurons()\n",
    "pe_dead.run(reset_fields=False, reset_weights=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot: Field size distribution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metric = Metric.AVG_NUM_FIELDS_PER_NEURON\n",
    "\n",
    "print(pe.eval_data.eval_metrics[metric].values[2])\n",
    "print(pe.eval_data.eval_metrics[metric].values[11])\n",
    "\n",
    "plot_distribution(pe.cans[2].field_sizes, nbins=np.arange(0, 10, step=0.05), y_lim=(0, 30))\n",
    "plt.figure()\n",
    "plot_distribution(pe.cans[11].field_sizes, nbins=np.arange(0, 10, step=0.05), y_lim=(0, 30))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluation of field location distribution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Config\n",
    "n_bins = 50\n",
    "use_sorted_ids = True\n",
    "\n",
    "# Code\n",
    "pos_error_mean = pe.eval_data.eval_metrics[Metric.POS_ERROR_MEAN].values\n",
    "pos_error_std = pe.eval_data.eval_metrics[Metric.POS_ERROR_STD].values\n",
    "net_ids_sorted = np.argsort(pos_error_mean)\n",
    "\n",
    "if use_sorted_ids:\n",
    "    net_id_range = net_ids_sorted\n",
    "else:\n",
    "    net_id_range = range(len(pe.cans))\n",
    "\n",
    "# net_id_range = [1]\n",
    "\n",
    "fig_kls, axs_kls = plt.subplots(nrows=4, ncols=4)\n",
    "fig_kls.tight_layout()\n",
    "\n",
    "fig_loc, axs_loc = plt.subplots(nrows=4, ncols=4)\n",
    "fig_loc.tight_layout()\n",
    "\n",
    "for i, i_net in enumerate(net_id_range):\n",
    "    # kls = get_prob_bins(pe.cans[i_net], 0.66, 1.8, num_bins=n_bins)\n",
    "    kls = calc_kls_locs(pe.cans[i_net], 0.66, pe.cans[i_net].p.env_length, num_bins=n_bins, lower_ppf=0.0, upper_ppf=1.0)\n",
    "    print(f'Network [{i_net}]: mean-kl = {np.mean(kls)}, std-kl = {np.std(kls)}, pos-error-mean = {pos_error_mean[i_net]}')\n",
    "\n",
    "    axs_x = int(i / 4)\n",
    "    axs_y = int(i % 4)\n",
    "    title = f'Net-{i_net}: kl-mean/std={np.mean(kls):.3f}/{np.std(kls):.3f},\\npos-error-mean={pos_error_mean[i_net]:.3f},\\npos-error-std={pos_error_std[i_net]:.3f}'\n",
    "\n",
    "    axs_kls[axs_x, axs_y].hist(kls, bins=10)\n",
    "    axs_kls[axs_x, axs_y].set_title(title)\n",
    "\n",
    "    # plot_distribution(pe.cans[i_net].field_locs, ax=axs[axs_x, axs_y], title=title, nbins=np.arange(0, 10, step=0.05))\n",
    "    plot_distribution(pe.cans[i_net].field_locs, ax=axs_loc[axs_x, axs_y], title=title, nbins=n_bins)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluation of KL-D Mean/Std for field sizes and locations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "#\n",
    "# 2-2: Distribution of field locations and sizes from original distributions\n",
    "#\n",
    "\n",
    "## Config\n",
    "evalutated_prop = 'locations'\n",
    "n_bins = 20\n",
    "\n",
    "## Code\n",
    "# fig, axs = plt.subplots(nrows=2, constrained_layout=True, figsize=(10, 5))\n",
    "fig, axs = plt.subplots(nrows=2, figsize=(10, 5))\n",
    "\n",
    "fig.add_subplot(111, frameon=False)\n",
    "# hide tick and tick label of the big axis\n",
    "plt.tick_params(labelcolor='none', which='both', top=False, bottom=False, left=False, right=False)\n",
    "plt.ylabel('KL-Divergence (mean/std)', fontsize='12', labelpad=44)\n",
    "plt.yticks([])\n",
    "\n",
    "if evalutated_prop == 'sizes':\n",
    "    fig.suptitle('KL-Divergence - Field size distribution vs. gamma distribution', fontsize='14', weight='bold')\n",
    "elif evalutated_prop == 'locations':\n",
    "    fig.suptitle('KL-Divergence - Field location distribution vs. uniform distribution', fontsize='14', weight='bold')\n",
    "\n",
    "kld_means = list()\n",
    "kld_stds = list()\n",
    "\n",
    "pos_error_mean = pe_many.eval_data.eval_metrics[Metric.POS_ERROR_MEAN].values\n",
    "net_ids_sorted = np.argsort(pos_error_mean)\n",
    "\n",
    "for i, i_net in enumerate(net_ids_sorted):\n",
    "    if evalutated_prop == 'sizes':\n",
    "        kls = calc_kls_sizes(pe_many.cans[i_net], 0.66, 1.8, num_bins=n_bins)\n",
    "    elif evalutated_prop == 'locations':\n",
    "        kls = calc_kls_locs(pe_many.cans[i_net], 0.66, pe_many.cans[i_net].p.env_length, num_bins=n_bins, lower_ppf=0.0, upper_ppf=1.0)\n",
    "    # print(f'Network [{i_net}]: mean-kl = {np.mean(kls)}, std-kl = {np.std(kls)}, pos-error-mean = {pos_error_mean[i_net]}')\n",
    "\n",
    "    kld_means.append(np.mean(kls))\n",
    "    kld_stds.append(np.std(kls))\n",
    "\n",
    "x = np.array(range(len(kld_means)))\n",
    "\n",
    "axs[0].errorbar(x, kld_means, kld_stds, fmt='o')\n",
    "xtick_labels = [f'{i:.2f}' for i in np.sort(pos_error_mean)]\n",
    "axs[0].set_xticks(x, xtick_labels)\n",
    "axs[0].set_xlabel('Mean Positional Error (m)', fontsize='12', labelpad=12)\n",
    "axs[0].set_title('Model A')\n",
    "\n",
    "# axs[0].set_ylabel('KL-Divergence (Mean/Std)', fontsize='12', labelpad=12)\n",
    "\n",
    "\n",
    "kld_means = list()\n",
    "kld_stds = list()\n",
    "\n",
    "pos_error_mean = pe_few.eval_data.eval_metrics[Metric.POS_ERROR_MEAN].values\n",
    "net_ids_sorted = np.argsort(pos_error_mean)\n",
    "\n",
    "for i, i_net in enumerate(net_ids_sorted):\n",
    "    if evalutated_prop == 'sizes':\n",
    "        kls = calc_kls_sizes(pe_few.cans[i_net], 0.66, 1.8, num_bins=n_bins)\n",
    "    elif evalutated_prop == 'locations':\n",
    "        kls = calc_kls_locs(pe_few.cans[i_net], 0.66, pe_few.cans[i_net].p.env_length, num_bins=n_bins, lower_ppf=0.0, upper_ppf=1.0)\n",
    "    # print(f'Network [{i_net}]: mean-kl = {np.mean(kls)}, std-kl = {np.std(kls)}, pos-error-mean = {pos_error_mean[i_net]}')\n",
    "\n",
    "    kld_means.append(np.mean(kls))\n",
    "    kld_stds.append(np.std(kls))\n",
    "\n",
    "# ax2 = axs.twiny()\n",
    "\n",
    "axs[1].errorbar(x+0.5, kld_means, kld_stds, fmt='o', color='C1')\n",
    "xtick_labels = [f'{i:.2f}' for i in np.sort(pos_error_mean)]\n",
    "axs[1].set_xticks(x+0.5, xtick_labels)\n",
    "axs[1].set_xlabel('Mean Positional Error (m)', fontsize='12', labelpad=12)\n",
    "axs[1].set_title('Model B')\n",
    "# axs[1].grid(linestyle='--')\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "fig.subplots_adjust(left=0.09, bottom=0.12, right=0.99, top=0.843, hspace=0.9)\n",
    "\n",
    "\n",
    "experiment_description = f'2-2_kld-field-{evalutated_prop}'\n",
    "fig_name = f'{DMSMF.__name__}_experiment_{experiment_description}.pdf'\n",
    "file_path = join(EXPERIMENT_FOLDERS[DMSMF.__name__], EXPERIMENT_SUBFOLDERS[FileType.FIGURE], fig_name)\n",
    "\n",
    "fig.savefig(file_path)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation of field location vs. bin location"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median [min] = 0.1264547677291432\n",
      "Median [max] = 0.1299440764851667\n",
      "Mean [min] = 0.12703949117053975\n",
      "Mean [max] = 0.12751071112333895\n"
     ]
    }
   ],
   "source": [
    "def get_field_loc_dist(net):\n",
    "    field_locs = (net.field_locs + 0.5 * net.p.disc_step) / net.p.disc_step\n",
    "    field_locs = np.where(field_locs % 1 > 0.5, 1 - field_locs % 1, field_locs % 1)\n",
    "    field_locs /= 2\n",
    "    field_locs[net.field_sizes == 0] = 0\n",
    "\n",
    "    return field_locs[field_locs > 0].flatten()\n",
    "\n",
    "\n",
    "pos_error_mean = pe.eval_data.eval_metrics[Metric.POS_ERROR_MEAN].values\n",
    "\n",
    "net_id_min = np.argmin(pos_error_mean)\n",
    "net_id_max = np.argmax(pos_error_mean)\n",
    "\n",
    "min_dists = get_field_loc_dist(pe.cans[net_id_min])\n",
    "max_dists = get_field_loc_dist(pe.cans[net_id_max])\n",
    "\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.violinplot(min_dists, showmeans=False, showextrema=True, showmedians=True)\n",
    "plt.title(f'Minimum error = {pos_error_mean[net_id_min]}')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.violinplot(max_dists, showmeans=False, showextrema=True, showmedians=True)\n",
    "plt.title(f'Maximum error = {pos_error_mean[net_id_max]}')\n",
    "\n",
    "\n",
    "print(f'Median [min] = {np.median(min_dists)}')\n",
    "print(f'Median [max] = {np.median(max_dists)}')\n",
    "\n",
    "print(f'Mean [min] = {np.mean(min_dists)}')\n",
    "print(f'Mean [max] = {np.mean(max_dists)}')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, figsize=(10, 5))\n",
    "\n",
    "fig.suptitle('Field-bin-center distance', fontsize='14', weight='bold')\n",
    "\n",
    "fig.add_subplot(111, frameon=False)\n",
    "# hide tick and tick label of the big axis\n",
    "plt.tick_params(labelcolor='none', which='both', top=False, bottom=False, left=False, right=False)\n",
    "plt.ylabel('Median distance (m)', fontsize='12', labelpad=44)\n",
    "plt.yticks([])\n",
    "\n",
    "## Calculate dist for many\n",
    "pos_error_mean = pe_many.eval_data.eval_metrics[Metric.POS_ERROR_MEAN].values\n",
    "sorted_ids = np.argsort(pos_error_mean)\n",
    "\n",
    "x = np.array(range(len(pos_error_mean)))\n",
    "\n",
    "median_bin_dists_many = {Statistics.MEAN: [], Statistics.MEDIAN: [], Statistics.STD: []}\n",
    "for i_net in sorted_ids:\n",
    "    min_dists_many = get_field_loc_dist(pe_many.cans[i_net])\n",
    "    # median_bin_dists_many.append(np.median(min_dists_many))\n",
    "    for stat in median_bin_dists_many.keys():\n",
    "        median_bin_dists_many[stat].append(getattr(np, stat)(min_dists_many))\n",
    "\n",
    "# axs[0].plot(median_bin_dists_many)\n",
    "axs[0].errorbar(x+0.5, median_bin_dists_many[Statistics.MEAN], median_bin_dists_many[Statistics.STD], fmt='o', color='C0')\n",
    "xtick_labels = [f'{i:.2f}' for i in np.sort(pos_error_mean)]\n",
    "axs[0].set_xticks(x, xtick_labels)\n",
    "axs[0].set_xlabel('Mean Positional Error of Network (m)', fontsize='12', labelpad=12)\n",
    "axs[0].set_title('Model A')\n",
    "\n",
    "## Same for few\n",
    "pos_error_mean = pe_few.eval_data.eval_metrics[Metric.POS_ERROR_MEAN].values\n",
    "sorted_ids = np.argsort(pos_error_mean)\n",
    "\n",
    "median_bin_dists_few = {Statistics.MEAN: [], Statistics.MEDIAN: [], Statistics.STD: []}\n",
    "for i_net in sorted_ids:\n",
    "    min_dists_few = get_field_loc_dist(pe_few.cans[i_net])\n",
    "    for stat in median_bin_dists_few.keys():\n",
    "        median_bin_dists_few[stat].append(getattr(np, stat)(min_dists_few))\n",
    "\n",
    "# axs[1].plot(median_bin_dists_few)\n",
    "axs[1].errorbar(x+0.5, median_bin_dists_few[Statistics.MEAN], median_bin_dists_few[Statistics.STD], fmt='o', color='C1')\n",
    "xtick_labels = [f'{i:.2f}' for i in np.sort(pos_error_mean)]\n",
    "axs[1].set_xticks(x, xtick_labels)\n",
    "axs[1].set_xlabel('Mean Positional Error of Network (m)', fontsize='12', labelpad=12)\n",
    "axs[1].set_title('Model B')\n",
    "\n",
    "# Adjust plot size\n",
    "fig.subplots_adjust(left=0.09, bottom=0.12, right=0.99, top=0.843, hspace=0.9)\n",
    "\n",
    "# Save plot\n",
    "experiment_description = f'2-2_field-bin-dist'\n",
    "fig_name = f'{DMSMF.__name__}_experiment_{experiment_description}.pdf'\n",
    "file_path = join(EXPERIMENT_FOLDERS[DMSMF.__name__], EXPERIMENT_SUBFOLDERS[FileType.FIGURE], fig_name)\n",
    "\n",
    "fig.savefig(file_path)\n",
    "\n",
    "# plt.title(f'Median distance between field locations and bin centers')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation of false positives/negatives"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x7fd8991f7040>]"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_error_mean = pe.eval_data.eval_metrics[Metric.POS_ERROR_MEAN].values\n",
    "sorted_ids = np.argsort(pos_error_mean)\n",
    "\n",
    "net_id_min = np.argmin(pos_error_mean)\n",
    "net_id_max = np.argmax(pos_error_mean)\n",
    "\n",
    "fig = plt.figure(1)\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(np.take(pe.eval_data.eval_metrics[Metric.POS_ERROR_MEAN].values, sorted_ids), 'x')\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(np.take(pe.eval_data.eval_metrics[Metric.ACTIVITY_FALSE_POSITIVES_NUM].values, sorted_ids), 'x', color='C1')\n",
    "ax2.plot(np.take(pe.eval_data.eval_metrics[Metric.ACTIVITY_FALSE_NEGATIVES_NUM].values, sorted_ids), 'x', color='C2')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, figsize=(12, 8))\n",
    "\n",
    "fig.suptitle('False positive/negative count per network', fontsize='14', weight='bold')\n",
    "\n",
    "fig.add_subplot(111, frameon=False)\n",
    "# hide tick and tick label of the big axis\n",
    "plt.tick_params(labelcolor='none', which='both', top=False, bottom=False, left=False, right=False)\n",
    "plt.ylabel('Median distance (m)', fontsize='12', labelpad=44)\n",
    "plt.yticks([])\n",
    "\n",
    "## Calculate dist for many\n",
    "pos_error_mean = pe_many.eval_data.eval_metrics[Metric.POS_ERROR_MEAN].values\n",
    "sorted_ids = np.argsort(pos_error_mean)\n",
    "\n",
    "x = np.array(range(len(pos_error_mean)))\n",
    "\n",
    "# axs[0].plot(np.take(pe_many.eval_data.eval_metrics[Metric.POS_ERROR_MEAN].values, sorted_ids), 'x')\n",
    "#\n",
    "# ax2 = axs[0].twinx()\n",
    "# ax2.plot(np.take(pe_many.eval_data.eval_metrics[Metric.ACTIVITY_FALSE_POSITIVES_NUM].values, sorted_ids), 'x', color='C1')\n",
    "# ax2.plot(np.take(pe_many.eval_data.eval_metrics[Metric.ACTIVITY_FALSE_NEGATIVES_NUM].values, sorted_ids), 'x', color='C2')\n",
    "axs[0].scatter(x, np.take(pe_many.eval_data.eval_metrics[Metric.POS_ERROR_MEAN].values, sorted_ids), facecolors='None', edgecolors=f'C0')\n",
    "\n",
    "ax2 = axs[0].twinx()\n",
    "ax2.scatter(x, np.take(pe_many.eval_data.eval_metrics[Metric.ACTIVITY_FALSE_POSITIVES_NUM].values, sorted_ids), facecolors='None', edgecolors=f'C1')\n",
    "ax2.scatter(x, np.take(pe_many.eval_data.eval_metrics[Metric.ACTIVITY_FALSE_NEGATIVES_NUM].values, sorted_ids), facecolors='None', edgecolors=f'C2')\n",
    "\n",
    "xtick_labels = [f'{i:.2f}' for i in np.sort(pos_error_mean)]\n",
    "axs[0].set_xticks(x, xtick_labels)\n",
    "axs[0].set_xlabel('Mean Positional Error of Network (m)', fontsize='12', labelpad=12)\n",
    "axs[0].set_title('Model A')\n",
    "\n",
    "## Same for few\n",
    "pos_error_mean = pe_few.eval_data.eval_metrics[Metric.POS_ERROR_MEAN].values\n",
    "sorted_ids = np.argsort(pos_error_mean)\n",
    "\n",
    "axs[1].scatter(x, np.take(pe_few.eval_data.eval_metrics[Metric.POS_ERROR_MEAN].values, sorted_ids), facecolors='None', edgecolors=f'C0')\n",
    "\n",
    "ax3 = axs[1].twinx()\n",
    "ax3.scatter(x, np.take(pe_few.eval_data.eval_metrics[Metric.ACTIVITY_FALSE_POSITIVES_NUM].values, sorted_ids), facecolors='None', edgecolors=f'C1')\n",
    "ax3.scatter(x, np.take(pe_few.eval_data.eval_metrics[Metric.ACTIVITY_FALSE_NEGATIVES_NUM].values, sorted_ids), facecolors='None', edgecolors=f'C2')\n",
    "\n",
    "xtick_labels = [f'{i:.2f}' for i in np.sort(pos_error_mean)]\n",
    "axs[1].set_xticks(x, xtick_labels)\n",
    "axs[1].set_xlabel('Mean Positional Error of Network (m)', fontsize='12', labelpad=12)\n",
    "axs[1].set_title('Model B')\n",
    "\n",
    "# Adjust plot size\n",
    "fig.subplots_adjust(left=0.09, bottom=0.12, right=0.99, top=0.843, hspace=0.9)\n",
    "\n",
    "# Save plot\n",
    "experiment_description = f'2-2_false-pos-neg'\n",
    "fig_name = f'{DMSMF.__name__}_experiment_{experiment_description}.pdf'\n",
    "file_path = join(EXPERIMENT_FOLDERS[DMSMF.__name__], EXPERIMENT_SUBFOLDERS[FileType.FIGURE], fig_name)\n",
    "\n",
    "fig.savefig(file_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation of perc unique field combinations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9520202  0.98579545 0.99368687 1.02714646 1.03598485 1.03977273\n",
      " 1.14267677 1.15340909 1.43813131 1.51641414 1.5719697  1.62058081\n",
      " 1.67424242 1.73989899 1.76010101 1.83143939 1.84090909 2.06060606\n",
      " 2.46275253 2.69255051]\n"
     ]
    }
   ],
   "source": [
    "pe = pe_few\n",
    "\n",
    "pos_error_mean = pe.eval_data.eval_metrics[Metric.POS_ERROR_MEAN].values\n",
    "sorted_ids = np.argsort(pos_error_mean)\n",
    "print(np.sort(pos_error_mean))\n",
    "\n",
    "for k in np.arange(0.001, 0.01, 0.001):\n",
    "    num_combs = []\n",
    "    for i in sorted_ids:\n",
    "\n",
    "        net = pe.cans[i]\n",
    "\n",
    "        arr = net.m > k\n",
    "\n",
    "        num_unique_field_combinations = len(np.unique(reduce(lambda a,b: 2*a+b, arr)))\n",
    "        perc_unique_field_combinations = num_unique_field_combinations / net.num_bins\n",
    "\n",
    "        num_combs.append(perc_unique_field_combinations)\n",
    "\n",
    "    plt.plot(num_combs)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3-3: Evaluation of lateral connection benefits in MSMF models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "plot_neuron_activity_static(pe_.cans[0], neuron_range=range(5), save_plot=True, experiment_num=18, fig_type_name='3-3-a')\n",
    "plot_neuron_activity_static(pe.cans[0], neuron_range=range(5), save_plot=True, experiment_num=4, fig_type_name='3-3-a')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation - Multi Run - MSMF Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "experiment_id = 'c'\n",
    "\n",
    "pe = ParallelEvaluationExecutor(experiment_id, DMSMF)\n",
    "\n",
    "pe.run()\n",
    "pe.save_data(show_plots=False, save_plots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Object (De-)Serialization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Object Serialization\n",
    "from msmfcode.evaluation.data import save_model_object\n",
    "\n",
    "save_model_object(pe, DMSMF, model_description='2-2_large-pos-std_many-fields', model_id='opt-05-167-08')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Object Deserialization\n",
    "from msmfcode.evaluation.data import load_model_object\n",
    "\n",
    "# pe_nlat = load_model_object(ParallelExecutor, DMSMF, model_description='experiment', model_id='single-14')\n",
    "pe = load_model_object(ParallelExecutor, DMSMF, model_description='experiment', model_id='single-18')\n",
    "\n",
    "\n",
    "# pe = load_model_object(ParallelExecutor, DMSMF, model_description='pos-error-zero', model_id='gen-0-ent-7')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Backup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for mean_error_pe, mean_error_pe_dead, net_id in (zip(pe.eval_data.eval_metrics[Metric.POS_ERROR_MEAN].values, pe_dead.eval_data.eval_metrics[Metric.POS_ERROR_MEAN].values, range(len(pe.eval_data.eval_metrics[Metric.POS_ERROR_MEAN].values)))):\n",
    "    print(f'CAN [{net_id}]: Mean Pos Error = {mean_error_pe:.3f}  |  {mean_error_pe_dead:.3f}  ||  {mean_error_pe_dead-mean_error_pe:.3f}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# bins = list(np.arange(0.25, 6, 0.25))\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# g = gamma(a=0.66, scale=1.8, loc=0)\n",
    "# lower_bound = g.ppf(0.01)\n",
    "# upper_bound = g.ppf(0.99)\n",
    "# N = 25\n",
    "# bins, step = np.linspace(lower_bound, upper_bound, N, retstep=True)\n",
    "#\n",
    "# bin_prob_neuron = get_prob_bins(pe.cans[10], bins)\n",
    "#\n",
    "#\n",
    "# bin_prob_gamma = np.zeros(len(bins))\n",
    "#\n",
    "# for i_bin, bin in enumerate(bins):\n",
    "#     if i_bin == 0:\n",
    "#         value_a = g.pdf(0.000000001)\n",
    "#     else:\n",
    "#         value_a = g.pdf(bins[i_bin-1])\n",
    "#     value_b = g.pdf(bin)\n",
    "#     avg = np.mean([value_a, value_b])\n",
    "#     bin_prob_gamma[i_bin] = avg\n",
    "#\n",
    "# bin_prob_gamma /= np.sum(bin_prob_gamma)\n",
    "\n",
    "\n",
    "# print(bin_prob_gamma)\n",
    "\n",
    "# Config\n",
    "n_bins = 40\n",
    "\n",
    "# Code\n",
    "pos_error_mean = pe.eval_data.eval_metrics[Metric.POS_ERROR_MEAN].values\n",
    "\n",
    "net_id_min = np.argmin(pos_error_mean)\n",
    "net_id_max = np.argmax(pos_error_mean)\n",
    "\n",
    "# net_id_min = 15\n",
    "# net_id_max = 10\n",
    "\n",
    "print(f'Calculating KL for minimum error net (mean-pos-error = {pos_error_mean[net_id_min]})')\n",
    "# kls_a = calc_kls_sizes(pe.cans[net_id_min], 0.66, 1.8, num_bins=20)\n",
    "kls_a = calc_kls_locs(pe.cans[net_id_min], 0.66, pe.cans[net_id_min].p.env_length, num_bins=50, lower_ppf=0.0, upper_ppf=1.0)\n",
    "print(f'Network [{net_id_min}]: mean-kl = {np.mean(kls_a)}, std-kl = {np.std(kls_a)}, pos-error-mean = {pos_error_mean[net_id_min]}')\n",
    "\n",
    "print(f'\\nCalculating KL for maximum error net (mean-pos-error = {pos_error_mean[net_id_max]})')\n",
    "# kls_b = calc_kls_sizes(pe.cans[net_id_max], 0.66, 1.8, num_bins=20)\n",
    "kls_b = calc_kls_locs(pe.cans[net_id_max], 0.66, pe.cans[net_id_max].p.env_length, num_bins=50, lower_ppf=0.0, upper_ppf=1.0)\n",
    "print(f'Network [{net_id_max}]: mean-kl = {np.mean(kls_b)}, std-kl = {np.std(kls_b)}, pos-error-mean = {pos_error_mean[net_id_max]}')\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1)\n",
    "fig.tight_layout()\n",
    "axs[0].hist(kls_a, bins=n_bins)\n",
    "axs[0].set_title(f'Net-{net_id_min} with minimal error = {pos_error_mean[net_id_min]:3f}')\n",
    "axs[1].hist(kls_b, bins=n_bins)\n",
    "axs[1].set_title(f'Net-{net_id_max} with maximal error = {pos_error_mean[net_id_max]:3f}')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Plot KLs for all networks\n",
    "\n",
    "# Config\n",
    "n_bins = 20\n",
    "use_sorted_ids = True\n",
    "\n",
    "# Code\n",
    "pos_error_mean = pe.eval_data.eval_metrics[Metric.POS_ERROR_MEAN].values\n",
    "pos_error_std = pe.eval_data.eval_metrics[Metric.POS_ERROR_STD].values\n",
    "net_ids_sorted = np.argsort(pos_error_mean)\n",
    "\n",
    "if use_sorted_ids:\n",
    "    net_id_range = net_ids_sorted\n",
    "else:\n",
    "    net_id_range = range(len(pe.cans))\n",
    "\n",
    "# net_id_min = np.argmin(pos_error_mean)\n",
    "# net_id_max = np.argmax(pos_error_mean)\n",
    "# net_id_range = [net_id_min, net_id_max]\n",
    "\n",
    "# net_id_range = [1]\n",
    "\n",
    "fig, axs = plt.subplots(nrows=4, ncols=4)\n",
    "fig.tight_layout()\n",
    "\n",
    "for i, i_net in enumerate(net_id_range):\n",
    "    kls = calc_kls_sizes(pe.cans[i_net], 0.66, 1.8, num_bins=n_bins)\n",
    "    # kls = calc_kls_locs(pe.cans[i_net], 0.66, pe.cans[i_net].p.env_length, num_bins=n_bins, lower_ppf=0.0, upper_ppf=1.0)\n",
    "    print(f'Network [{i_net}]: mean-kl = {np.mean(kls)}, std-kl = {np.std(kls)}, pos-error-mean = {pos_error_mean[i_net]}')\n",
    "\n",
    "    axs_x = int(i / 4)\n",
    "    axs_y = int(i % 4)\n",
    "    axs[axs_x, axs_y].hist(kls, bins=n_bins)\n",
    "    axs[axs_x, axs_y].set_title(f'Net-{i_net}: kl-mean/std={np.mean(kls):.3f}/{np.std(kls):.3f},\\npos-error-mean={pos_error_mean[i_net]:.3f},\\npos-error-std={pos_error_std[i_net]:.3f}')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
